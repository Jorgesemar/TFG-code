{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Configuración del dispositivo (CPU o GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Diccionario para mapear posiciones a índices\n",
    "position_to_index = {\n",
    "    '5050_guard': 0,\n",
    "    'back1': 1,\n",
    "    'back2': 2,\n",
    "    'closed_guard1': 3,\n",
    "    'closed_guard2': 4,\n",
    "    'half_guard1': 5,\n",
    "    'half_guard2': 6,\n",
    "    'mount1': 7,\n",
    "    'mount2': 8,\n",
    "    'open_guard1': 9,\n",
    "    'open_guard2': 10,\n",
    "    'side_control1': 11,\n",
    "    'side_control2': 12,\n",
    "    'standing': 13,\n",
    "    'takedown1': 14,\n",
    "    'takedown2': 15,\n",
    "    'turtle1': 16,\n",
    "    'turtle2': 17\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_annotations(file_path):\n",
    "    \"\"\"\n",
    "    Carga las anotaciones preprocesadas desde un archivo JSON.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image):\n",
    "    \"\"\"\n",
    "    Quita el fondo de una imagen utilizando segmentación de contornos con OpenCV.\n",
    "    \"\"\"\n",
    "    # Convertir imagen PIL a array de NumPy\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Aplicar un umbral para segmentar la imagen\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Crear una máscara vacía\n",
    "    mask = np.zeros_like(gray)\n",
    "\n",
    "    # Dibujar el contorno más grande en la máscara\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Aplicar la máscara a la imagen original\n",
    "    result = cv2.bitwise_and(image_np, image_np, mask=mask)\n",
    "\n",
    "    # Convertir de nuevo a imagen PIL\n",
    "    return Image.fromarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, annotations, seq_length=10, position_to_index=None):\n",
    "        \"\"\"\n",
    "        Inicializa el dataset para análisis de secuencias.\n",
    "        \"\"\"\n",
    "        self.annotations = annotations\n",
    "        self.seq_length = seq_length\n",
    "        self.position_to_index = position_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Devuelve el número de secuencias disponibles.\n",
    "        \"\"\"\n",
    "        return len(self.annotations) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Devuelve una secuencia de datos y su etiqueta correspondiente.\n",
    "        \"\"\"\n",
    "        sequence = [\n",
    "            self.annotations[idx + i]['Pose1'] + self.annotations[idx + i]['Pose2']\n",
    "            for i in range(self.seq_length)\n",
    "        ]\n",
    "        sequence = torch.tensor(sequence).view(self.seq_length, -1)\n",
    "        label_str = self.annotations[idx + self.seq_length - 1]['Position']\n",
    "        label = self.position_to_index[label_str]\n",
    "        return sequence, torch.tensor(label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        \"\"\"\n",
    "        Inicializa el modelo LSTM.\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define la pasada hacia adelante del modelo.\n",
    "        \"\"\"\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        final_output = lstm_out[:, -1, :]\n",
    "        return self.fc(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_lstm(train_loader, val_loader, model, criterion, optimizer, num_epochs=25, patience=5):\n",
    "    \"\"\"\n",
    "    Entrena y valida el modelo LSTM, aplicando early stopping.\n",
    "    \"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}')\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Validation Loss: {val_loss}')\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_lstm_model.pth')\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_kfold_lstm(dataset, k_folds=5, batch_size=16, num_epochs=25, patience=5):\n",
    "    \"\"\"\n",
    "    Realiza validación cruzada con K-Fold para el modelo LSTM.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "\n",
    "        input_size = 102  # 34 puntos clave x 3 coordenadas\n",
    "        hidden_size = 128\n",
    "        output_size = len(position_to_index)\n",
    "\n",
    "        model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        train_and_validate_lstm(train_loader, val_loader, model, criterion, optimizer, num_epochs=num_epochs, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/25, Loss: 0.844924037750036\n",
      "Validation Loss: 0.5425993465428843\n",
      "Epoch 2/25, Loss: 0.34174617702567883\n",
      "Validation Loss: 0.23433765280373106\n",
      "Epoch 3/25, Loss: 0.2294065505723722\n",
      "Validation Loss: 0.17555575729325423\n",
      "Epoch 4/25, Loss: 0.17973897410981568\n",
      "Validation Loss: 0.14013273709808005\n",
      "Epoch 5/25, Loss: 0.13197529553369705\n",
      "Validation Loss: 0.08146314235927393\n",
      "Epoch 6/25, Loss: 0.11842318309123409\n",
      "Validation Loss: 0.11764338512733388\n",
      "Epoch 7/25, Loss: 0.10020242592775426\n",
      "Validation Loss: 0.10198479420239952\n",
      "Epoch 8/25, Loss: 0.08215252478832014\n",
      "Validation Loss: 0.07265839341029996\n",
      "Epoch 9/25, Loss: 0.07572244716049245\n",
      "Validation Loss: 0.060198580578222464\n",
      "Epoch 10/25, Loss: 0.07524538143084394\n",
      "Validation Loss: 0.03975790597522223\n",
      "Epoch 11/25, Loss: 0.058114879156189826\n",
      "Validation Loss: 0.04195927360624435\n",
      "Epoch 12/25, Loss: 0.05915015982120425\n",
      "Validation Loss: 0.10217493696277344\n",
      "Epoch 13/25, Loss: 0.05071203018317967\n",
      "Validation Loss: 0.028703075885936718\n",
      "Epoch 14/25, Loss: 0.051699709023803136\n",
      "Validation Loss: 0.031498504302855945\n",
      "Epoch 15/25, Loss: 0.04260349756027421\n",
      "Validation Loss: 0.018834354529295497\n",
      "Epoch 16/25, Loss: 0.041617591650440586\n",
      "Validation Loss: 0.04689871867290395\n",
      "Epoch 17/25, Loss: 0.037388607308814874\n",
      "Validation Loss: 0.03840387297723874\n",
      "Epoch 18/25, Loss: 0.04743860472491655\n",
      "Validation Loss: 0.03950507524465354\n",
      "Epoch 19/25, Loss: 0.03049040378033896\n",
      "Validation Loss: 0.02376812762062881\n",
      "Epoch 20/25, Loss: 0.03273201762045381\n",
      "Validation Loss: 0.02329027144836412\n",
      "Early stopping\n",
      "Fold 2/5\n",
      "Epoch 1/25, Loss: 0.833141298574863\n",
      "Validation Loss: 0.4242200392686436\n",
      "Epoch 2/25, Loss: 0.3508632339555933\n",
      "Validation Loss: 0.2515394277646624\n",
      "Epoch 3/25, Loss: 0.22477516520353452\n",
      "Validation Loss: 0.1852764344423103\n",
      "Epoch 4/25, Loss: 0.1747562110173497\n",
      "Validation Loss: 0.13268234297981982\n",
      "Epoch 5/25, Loss: 0.1384008162141524\n",
      "Validation Loss: 0.08290753887819892\n",
      "Epoch 6/25, Loss: 0.1169018314449357\n",
      "Validation Loss: 0.13838291249981938\n",
      "Epoch 7/25, Loss: 0.09636379611603904\n",
      "Validation Loss: 0.04670302255534279\n",
      "Epoch 8/25, Loss: 0.08417391166652144\n",
      "Validation Loss: 0.09023997022455969\n",
      "Epoch 9/25, Loss: 0.07617548242856402\n",
      "Validation Loss: 0.06662002550082972\n",
      "Epoch 10/25, Loss: 0.06821994710599943\n",
      "Validation Loss: 0.08104882222480352\n",
      "Epoch 11/25, Loss: 0.0629198053140093\n",
      "Validation Loss: 0.04012174510346439\n",
      "Epoch 12/25, Loss: 0.05647813889726577\n",
      "Validation Loss: 0.04250993025224218\n",
      "Epoch 13/25, Loss: 0.05028285188980402\n",
      "Validation Loss: 0.044717803932196966\n",
      "Epoch 14/25, Loss: 0.050477392436519136\n",
      "Validation Loss: 0.03712504599234319\n",
      "Epoch 15/25, Loss: 0.04542074241585897\n",
      "Validation Loss: 0.025383342735216453\n",
      "Epoch 16/25, Loss: 0.03849139023561401\n",
      "Validation Loss: 0.05440583598757424\n",
      "Epoch 17/25, Loss: 0.040267541932216974\n",
      "Validation Loss: 0.021162316983444403\n",
      "Epoch 18/25, Loss: 0.035790159939608664\n",
      "Validation Loss: 0.04457883206852562\n",
      "Epoch 19/25, Loss: 0.03311156860888021\n",
      "Validation Loss: 0.018058872514533815\n",
      "Epoch 20/25, Loss: 0.03688871772077805\n",
      "Validation Loss: 0.03191486654696986\n",
      "Epoch 21/25, Loss: 0.03274006078043046\n",
      "Validation Loss: 0.024512785013048752\n",
      "Epoch 22/25, Loss: 0.030184138897212626\n",
      "Validation Loss: 0.014984845380455762\n",
      "Epoch 23/25, Loss: 0.028910957391231895\n",
      "Validation Loss: 0.010549852672112418\n",
      "Epoch 24/25, Loss: 0.03338848617955858\n",
      "Validation Loss: 0.02251714267839579\n",
      "Epoch 25/25, Loss: 0.03127410945498044\n",
      "Validation Loss: 0.0455617989452265\n",
      "Fold 3/5\n",
      "Epoch 1/25, Loss: 0.8626792498621771\n",
      "Validation Loss: 0.4906765863415518\n",
      "Epoch 2/25, Loss: 0.3623994400760944\n",
      "Validation Loss: 0.3809661632024297\n",
      "Epoch 3/25, Loss: 0.2314568691058614\n",
      "Validation Loss: 0.2655222938282145\n",
      "Epoch 4/25, Loss: 0.1751806119342382\n",
      "Validation Loss: 0.11168624434351031\n",
      "Epoch 5/25, Loss: 0.13925171056890143\n",
      "Validation Loss: 0.13755946569043614\n",
      "Epoch 6/25, Loss: 0.11468460989210819\n",
      "Validation Loss: 0.1528474469166161\n",
      "Epoch 7/25, Loss: 0.0971433091573322\n",
      "Validation Loss: 0.050343846296025334\n",
      "Epoch 8/25, Loss: 0.0914089696672798\n",
      "Validation Loss: 0.10302721748161899\n",
      "Epoch 9/25, Loss: 0.07353569539230749\n",
      "Validation Loss: 0.06607022645515975\n",
      "Epoch 10/25, Loss: 0.06912006668989451\n",
      "Validation Loss: 0.045757273402331496\n",
      "Epoch 11/25, Loss: 0.06165686172853029\n",
      "Validation Loss: 0.0866178585779026\n",
      "Epoch 12/25, Loss: 0.05643361030894072\n",
      "Validation Loss: 0.023789279835042462\n",
      "Epoch 13/25, Loss: 0.055254779047179826\n",
      "Validation Loss: 0.04684494209188279\n",
      "Epoch 14/25, Loss: 0.04512952456351528\n",
      "Validation Loss: 0.032520052462347834\n",
      "Epoch 15/25, Loss: 0.04633225690299865\n",
      "Validation Loss: 0.016144611291773015\n",
      "Epoch 16/25, Loss: 0.0417802876711495\n",
      "Validation Loss: 0.025818275706755708\n",
      "Epoch 17/25, Loss: 0.03631007797918068\n",
      "Validation Loss: 0.01969018422692811\n",
      "Epoch 18/25, Loss: 0.042457006057833924\n",
      "Validation Loss: 0.019186247332646\n",
      "Epoch 19/25, Loss: 0.03711312720270857\n",
      "Validation Loss: 0.014766255332984474\n",
      "Epoch 20/25, Loss: 0.03488036792690697\n",
      "Validation Loss: 0.019095143460499054\n",
      "Epoch 21/25, Loss: 0.027591533875389346\n",
      "Validation Loss: 0.03522822452163016\n",
      "Epoch 22/25, Loss: 0.02975004666395319\n",
      "Validation Loss: 0.012810809087989636\n",
      "Epoch 23/25, Loss: 0.03132993188168679\n",
      "Validation Loss: 0.04404402865891844\n",
      "Epoch 24/25, Loss: 0.02692625148045674\n",
      "Validation Loss: 0.01762515276109944\n",
      "Epoch 25/25, Loss: 0.028807558835869117\n",
      "Validation Loss: 0.027224034830828307\n",
      "Fold 4/5\n",
      "Epoch 1/25, Loss: 0.846309342392264\n",
      "Validation Loss: 0.40755731945440854\n",
      "Epoch 2/25, Loss: 0.34321172854466875\n",
      "Validation Loss: 0.2616257727645546\n",
      "Epoch 3/25, Loss: 0.2283265198342657\n",
      "Validation Loss: 0.16399930840532678\n",
      "Epoch 4/25, Loss: 0.17118050212379327\n",
      "Validation Loss: 0.08830503975086508\n",
      "Epoch 5/25, Loss: 0.1386774841090932\n",
      "Validation Loss: 0.09238972499070194\n",
      "Epoch 6/25, Loss: 0.11185502012783194\n",
      "Validation Loss: 0.08439685095417272\n",
      "Epoch 7/25, Loss: 0.09993629927816969\n",
      "Validation Loss: 0.05647012036067168\n",
      "Epoch 8/25, Loss: 0.08222479291478269\n",
      "Validation Loss: 0.07985849298660976\n",
      "Epoch 9/25, Loss: 0.07316084763943884\n",
      "Validation Loss: 0.0490087675954029\n",
      "Epoch 10/25, Loss: 0.0628335024132043\n",
      "Validation Loss: 0.054014283884334505\n",
      "Epoch 11/25, Loss: 0.06530068531232364\n",
      "Validation Loss: 0.06493551173977048\n",
      "Epoch 12/25, Loss: 0.05695080700401536\n",
      "Validation Loss: 0.02705249260552838\n",
      "Epoch 13/25, Loss: 0.04921644858178846\n",
      "Validation Loss: 0.0321661824698178\n",
      "Epoch 14/25, Loss: 0.045109946597189775\n",
      "Validation Loss: 0.033943133402235134\n",
      "Epoch 15/25, Loss: 0.047481473207934465\n",
      "Validation Loss: 0.0192321305107116\n",
      "Epoch 16/25, Loss: 0.042211094237958345\n",
      "Validation Loss: 0.01970659585133549\n",
      "Epoch 17/25, Loss: 0.040278858734229275\n",
      "Validation Loss: 0.04250894870266277\n",
      "Epoch 18/25, Loss: 0.03522129717748993\n",
      "Validation Loss: 0.01800289506891994\n",
      "Epoch 19/25, Loss: 0.03428917875930928\n",
      "Validation Loss: 0.24571455680250606\n",
      "Epoch 20/25, Loss: 0.029942101132301526\n",
      "Validation Loss: 0.05136054320015817\n",
      "Epoch 21/25, Loss: 0.03482086511920326\n",
      "Validation Loss: 0.016711001131486866\n",
      "Epoch 22/25, Loss: 0.030014021387292245\n",
      "Validation Loss: 0.08536277451234117\n",
      "Epoch 23/25, Loss: 0.025917741319353996\n",
      "Validation Loss: 0.12326223061474567\n",
      "Epoch 24/25, Loss: 0.02490401407270157\n",
      "Validation Loss: 0.014085976438854628\n",
      "Epoch 25/25, Loss: 0.02955738631847318\n",
      "Validation Loss: 0.04591096954820342\n",
      "Fold 5/5\n",
      "Epoch 1/25, Loss: 0.8442224584836958\n",
      "Validation Loss: 0.531981551987382\n",
      "Epoch 2/25, Loss: 0.33270773657656605\n",
      "Validation Loss: 0.21741960105427283\n",
      "Epoch 3/25, Loss: 0.218161841789027\n",
      "Validation Loss: 0.21750258163549432\n",
      "Epoch 4/25, Loss: 0.16571322380641773\n",
      "Validation Loss: 0.10344678975033067\n",
      "Epoch 5/25, Loss: 0.13297777207632067\n",
      "Validation Loss: 0.11064738276515981\n",
      "Epoch 6/25, Loss: 0.11185607720947105\n",
      "Validation Loss: 0.0805450542745742\n",
      "Epoch 7/25, Loss: 0.09104217507884524\n",
      "Validation Loss: 0.07220702586922054\n",
      "Epoch 8/25, Loss: 0.08675463525020809\n",
      "Validation Loss: 0.13870532916591188\n",
      "Epoch 9/25, Loss: 0.07262870820646322\n",
      "Validation Loss: 0.08075154299935747\n",
      "Epoch 10/25, Loss: 0.06490117412148023\n",
      "Validation Loss: 0.05693809820414047\n",
      "Epoch 11/25, Loss: 0.06390780369878393\n",
      "Validation Loss: 0.04187802397954626\n",
      "Epoch 12/25, Loss: 0.04967775252441248\n",
      "Validation Loss: 0.025553363429796482\n",
      "Epoch 13/25, Loss: 0.053180188232204884\n",
      "Validation Loss: 0.03081807433217943\n",
      "Epoch 14/25, Loss: 0.04558014006007668\n",
      "Validation Loss: 0.0371853179388155\n",
      "Epoch 15/25, Loss: 0.0446762110147199\n",
      "Validation Loss: 0.13591265242172376\n",
      "Epoch 16/25, Loss: 0.03934031332294082\n",
      "Validation Loss: 0.06884313722749134\n",
      "Epoch 17/25, Loss: 0.03861966152843369\n",
      "Validation Loss: 0.08248163993380923\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal para ejecutar la validación cruzada con el modelo LSTM.\n",
    "    \"\"\"\n",
    "    annotations_path = '../mnt/V3/annotations/annotations_preprocessed.json'\n",
    "    annotations = load_annotations(annotations_path)\n",
    "\n",
    "    seq_length = 10\n",
    "    dataset = SequenceDataset(annotations, seq_length=seq_length, position_to_index=position_to_index)\n",
    "\n",
    "    cross_validation_kfold_lstm(dataset, k_folds=5, batch_size=16, num_epochs=25, patience=5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

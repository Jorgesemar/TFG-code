{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision.models import vgg16\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Transformaciones de datos\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(file_path):\n",
    "    \"\"\"\n",
    "    Carga las anotaciones preprocesadas desde un archivo JSON.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkeletonDataset(Dataset):\n",
    "    def __init__(self, annotations, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Inicializa el dataset para análisis de poses esqueléticas.\n",
    "        \"\"\"\n",
    "        self.annotations = annotations\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Devuelve el tamaño del dataset.\n",
    "        \"\"\"\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Devuelve una imagen y su correspondiente vector de poses concatenadas.\n",
    "        \"\"\"\n",
    "        image_name = self.annotations[idx]['Image'] + '.jpg'\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        pose1 = self.annotations[idx]['Pose1']\n",
    "        pose2 = self.annotations[idx]['Pose2']\n",
    "\n",
    "        # Quitar fondo de la imagen\n",
    "        image = remove_background(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        pose = pose1 + pose2\n",
    "        pose = torch.tensor(pose).view(-1)  # Vectorizar las poses\n",
    "        return image, pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image):\n",
    "    \"\"\"\n",
    "    Quita el fondo de una imagen utilizando técnicas de segmentación de contornos con OpenCV.\n",
    "    \"\"\"\n",
    "    # Convertir imagen PIL a array de NumPy\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Aplicar un umbral para segmentar la imagen\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Crear una máscara vacía\n",
    "    mask = np.zeros_like(gray)\n",
    "\n",
    "    # Dibujar el contorno más grande en la máscara\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Aplicar la máscara a la imagen original\n",
    "    result = cv2.bitwise_and(image_np, image_np, mask=mask)\n",
    "\n",
    "    # Convertir de nuevo a imagen PIL\n",
    "    return Image.fromarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16ForPose(nn.Module):\n",
    "    def __init__(self, num_keypoints=102):\n",
    "        \"\"\"\n",
    "        Modifica VGG16 para predecir directamente puntos clave de poses (102 valores).\n",
    "        \"\"\"\n",
    "        super(VGG16ForPose, self).__init__()\n",
    "        self.backbone = vgg16(pretrained=True).features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_keypoints)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pasada hacia adelante del modelo.\n",
    "        \"\"\"\n",
    "        x = self.backbone(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device):\n",
    "    \"\"\"\n",
    "    Entrena el modelo durante una época.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AMP para precisión mixta\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    return running_loss / len(train_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, scaler, device):\n",
    "    \"\"\"\n",
    "    Valida el modelo durante una época.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    return val_loss / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(train_loader, val_loader, model, criterion, optimizer, scaler, device, num_epochs=25, patience=5):\n",
    "    \"\"\"\n",
    "    Entrena y valida el modelo, implementando early stopping. Calcula métricas adicionales.\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA no está disponible. Asegúrate de que tu GPU esté configurada correctamente.\")\n",
    "    else:\n",
    "        print(f\"Usando GPU: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    epoch_results = []  # Para almacenar los resultados de cada época\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Entrenamiento\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')\n",
    "\n",
    "        # Validación\n",
    "        val_loss = validate_one_epoch(model, val_loader, criterion, scaler, device)\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Calcular métricas adicionales en el conjunto de validación\n",
    "        y_true, y_pred = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                y_true.extend(targets.cpu().numpy())\n",
    "                y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        y_true = np.array(y_true).reshape(-1, 102)  # Convertir a formato batch_size x 102\n",
    "        y_pred = np.array(y_pred).reshape(-1, 102)\n",
    "\n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        std_ae = np.mean(np.abs(y_true - y_pred), axis=1).std()\n",
    "\n",
    "        print(f'Metrics -> MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}, STD AE: {std_ae:.4f}')\n",
    "\n",
    "        # Guardar resultados de la época\n",
    "        epoch_results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'mae': mae,\n",
    "            'mse': mse,\n",
    "            'r2': r2,\n",
    "            'std_ae': std_ae\n",
    "        })\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "            torch.save(model.state_dict(), 'vgg16_best_model.pth')\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Guardar resultados en un archivo CSV\n",
    "    with open('epoch_results.csv', 'a', newline='') as csvfile:\n",
    "        fieldnames = ['epoch', 'train_loss', 'val_loss', 'mae', 'mse', 'r2', 'std_ae']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(epoch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_kfold(dataset, k_folds=5, batch_size=8, num_epochs=25, patience=5):\n",
    "    \"\"\"\n",
    "    Realiza validación cruzada con K-Fold en el dataset y utiliza múltiples GPUs.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Usando {torch.cuda.device_count()} GPUs\")\n",
    "\n",
    "    num_workers = 4\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_subset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            \n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        model = VGG16ForPose(num_keypoints=102).to(device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        train_and_validate(train_loader, val_loader, model, criterion, optimizer, scaler, device, num_epochs, patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.01611253821070558\n",
      "Validation Loss: 0.013531259782695275\n",
      "Epoch 2/25, Loss: 0.009558142768751306\n",
      "Validation Loss: 0.008524348457556808\n",
      "Epoch 3/25, Loss: 0.007512813944025657\n",
      "Validation Loss: 0.0070005322940907685\n",
      "Epoch 4/25, Loss: 0.006225689877728949\n",
      "Validation Loss: 0.005846129299876266\n",
      "Epoch 5/25, Loss: 0.005409117011333794\n",
      "Validation Loss: 0.005065812594349092\n",
      "Epoch 6/25, Loss: 0.0047144331753104\n",
      "Validation Loss: 0.00455638022444485\n",
      "Epoch 7/25, Loss: 0.004206075403196998\n",
      "Validation Loss: 0.004315639101407997\n",
      "Epoch 8/25, Loss: 0.003804756429000767\n",
      "Validation Loss: 0.00408530786693083\n",
      "Epoch 9/25, Loss: 0.003462969511048952\n",
      "Validation Loss: 0.0037049341363154954\n",
      "Epoch 10/25, Loss: 0.0031801171279985524\n",
      "Validation Loss: 0.003557995717702434\n",
      "Epoch 11/25, Loss: 0.0029444977487532126\n",
      "Validation Loss: 0.003343730706971499\n",
      "Epoch 12/25, Loss: 0.002724811281416246\n",
      "Validation Loss: 0.0032343056724440386\n",
      "Epoch 13/25, Loss: 0.0025306374819807575\n",
      "Validation Loss: 0.00310880390598924\n",
      "Epoch 14/25, Loss: 0.0023781784188679897\n",
      "Validation Loss: 0.002948484921691773\n",
      "Epoch 15/25, Loss: 0.002237386855260467\n",
      "Validation Loss: 0.0028911448802392274\n",
      "Epoch 16/25, Loss: 0.0021176710052384132\n",
      "Validation Loss: 0.002808877080620995\n",
      "Epoch 17/25, Loss: 0.00200317607410956\n",
      "Validation Loss: 0.0027725119187182908\n",
      "Epoch 18/25, Loss: 0.001912466338354853\n",
      "Validation Loss: 0.0027636069487198445\n",
      "Epoch 19/25, Loss: 0.001820990121201038\n",
      "Validation Loss: 0.002737762940748311\n",
      "Epoch 20/25, Loss: 0.0017413606221593693\n",
      "Validation Loss: 0.0026400078078316525\n",
      "Epoch 21/25, Loss: 0.0016602938709302424\n",
      "Validation Loss: 0.0025817765649510573\n",
      "Epoch 22/25, Loss: 0.0015898696123288402\n",
      "Validation Loss: 0.002619607051015554\n",
      "Epoch 23/25, Loss: 0.001527997787513556\n",
      "Validation Loss: 0.0025589094792689516\n",
      "Epoch 24/25, Loss: 0.0014596709237622693\n",
      "Validation Loss: 0.002551848695351961\n",
      "Epoch 25/25, Loss: 0.0014068283518573576\n",
      "Validation Loss: 0.0025560878666077654\n",
      "Fold 2/5\n",
      "Epoch 1/25, Loss: 0.016305317331704334\n",
      "Validation Loss: 0.011598922348917273\n",
      "Epoch 2/25, Loss: 0.009496980281198728\n",
      "Validation Loss: 0.008361909921978876\n",
      "Epoch 3/25, Loss: 0.0074506915864689695\n",
      "Validation Loss: 0.007477229866472755\n",
      "Epoch 4/25, Loss: 0.006187333998229435\n",
      "Validation Loss: 0.0058346913497367035\n",
      "Epoch 5/25, Loss: 0.005297577853221285\n",
      "Validation Loss: 0.00522841351235217\n",
      "Epoch 6/25, Loss: 0.00462463888786405\n",
      "Validation Loss: 0.004596418551340669\n",
      "Epoch 7/25, Loss: 0.004135915280212122\n",
      "Validation Loss: 0.004343873958207476\n",
      "Epoch 8/25, Loss: 0.0037858307368129392\n",
      "Validation Loss: 0.003975114108067123\n",
      "Epoch 9/25, Loss: 0.003524548006064522\n",
      "Validation Loss: 0.003964296890157011\n",
      "Epoch 10/25, Loss: 0.0032421908262342666\n",
      "Validation Loss: 0.0036065795774986907\n",
      "Epoch 11/25, Loss: 0.0030211079612254264\n",
      "Validation Loss: 0.0034732215119875533\n",
      "Epoch 12/25, Loss: 0.0028164112385302975\n",
      "Validation Loss: 0.0033617888941754105\n",
      "Epoch 13/25, Loss: 0.0026519148552570514\n",
      "Validation Loss: 0.0031591294004594496\n",
      "Epoch 14/25, Loss: 0.0024804828207881675\n",
      "Validation Loss: 0.0031079137444231927\n",
      "Epoch 15/25, Loss: 0.002333590519464558\n",
      "Validation Loss: 0.0029882893024032087\n",
      "Epoch 16/25, Loss: 0.0022064238758806812\n",
      "Validation Loss: 0.00291874053833067\n",
      "Epoch 17/25, Loss: 0.002102114084268\n",
      "Validation Loss: 0.002844492616788506\n",
      "Epoch 18/25, Loss: 0.0020021028158679123\n",
      "Validation Loss: 0.0027957350898746808\n",
      "Epoch 19/25, Loss: 0.0019203082118121157\n",
      "Validation Loss: 0.0028150250477680583\n",
      "Epoch 20/25, Loss: 0.0018376273748369088\n",
      "Validation Loss: 0.0027063513993410573\n",
      "Epoch 21/25, Loss: 0.0017557037126150435\n",
      "Validation Loss: 0.0026745613219297712\n",
      "Epoch 22/25, Loss: 0.0016849162329047663\n",
      "Validation Loss: 0.002652132467312958\n",
      "Epoch 23/25, Loss: 0.0016111823571183775\n",
      "Validation Loss: 0.0027130026358408296\n",
      "Epoch 24/25, Loss: 0.001553292824400995\n",
      "Validation Loss: 0.0025749049461576924\n",
      "Epoch 25/25, Loss: 0.001502070445740599\n",
      "Validation Loss: 0.0026193237177599693\n",
      "Fold 3/5\n",
      "Epoch 1/25, Loss: 0.016451115189809126\n",
      "Validation Loss: 0.011181200822641221\n",
      "Epoch 2/25, Loss: 0.00938578368353291\n",
      "Validation Loss: 0.008435988337254351\n",
      "Epoch 3/25, Loss: 0.007656225192939709\n",
      "Validation Loss: 0.0072407269774374325\n",
      "Epoch 4/25, Loss: 0.0066882168062161315\n",
      "Validation Loss: 0.00648199438111772\n",
      "Epoch 5/25, Loss: 0.005858458481053435\n",
      "Validation Loss: 0.00565691975068758\n",
      "Epoch 6/25, Loss: 0.005219463710125864\n",
      "Validation Loss: 0.00504663880953852\n",
      "Epoch 7/25, Loss: 0.004636874822704206\n",
      "Validation Loss: 0.004683032812295341\n",
      "Epoch 8/25, Loss: 0.004165546378973448\n",
      "Validation Loss: 0.00440040365425015\n",
      "Epoch 9/25, Loss: 0.003852376803723676\n",
      "Validation Loss: 0.004150538284809634\n",
      "Epoch 10/25, Loss: 0.003611868291093669\n",
      "Validation Loss: 0.003951132950689005\n",
      "Epoch 11/25, Loss: 0.003390208266001585\n",
      "Validation Loss: 0.003706136940670995\n",
      "Epoch 12/25, Loss: 0.0031654098920059206\n",
      "Validation Loss: 0.0035418312878998316\n",
      "Epoch 13/25, Loss: 0.00288776001595947\n",
      "Validation Loss: 0.003363498617487566\n",
      "Epoch 14/25, Loss: 0.0026694080616713254\n",
      "Validation Loss: 0.003222729131697484\n",
      "Epoch 15/25, Loss: 0.002499879909604024\n",
      "Validation Loss: 0.003190237612020898\n",
      "Epoch 16/25, Loss: 0.002339028523271591\n",
      "Validation Loss: 0.0029976811229243823\n",
      "Epoch 17/25, Loss: 0.002201838794300503\n",
      "Validation Loss: 0.0028930728702258024\n",
      "Epoch 18/25, Loss: 0.002097828426379977\n",
      "Validation Loss: 0.002854098398812987\n",
      "Epoch 19/25, Loss: 0.001999023370536269\n",
      "Validation Loss: 0.0028321304359090914\n",
      "Epoch 20/25, Loss: 0.0018985992470363295\n",
      "Validation Loss: 0.0027758289060746738\n",
      "Epoch 21/25, Loss: 0.0018114467966694327\n",
      "Validation Loss: 0.002702831944277634\n",
      "Epoch 22/25, Loss: 0.001723403270300637\n",
      "Validation Loss: 0.002719360289565657\n",
      "Epoch 23/25, Loss: 0.001647646465870136\n",
      "Validation Loss: 0.002731043212888563\n",
      "Epoch 24/25, Loss: 0.001584972949237984\n",
      "Validation Loss: 0.0026724620694817294\n",
      "Epoch 25/25, Loss: 0.0015223094892206255\n",
      "Validation Loss: 0.0026081022732205015\n",
      "Fold 4/5\n",
      "Epoch 1/25, Loss: 0.01638002947546203\n",
      "Validation Loss: 0.012751384988380316\n",
      "Epoch 2/25, Loss: 0.00988365496544993\n",
      "Validation Loss: 0.008800217410647607\n",
      "Epoch 3/25, Loss: 0.007417443441673107\n",
      "Validation Loss: 0.0066577497571326145\n",
      "Epoch 4/25, Loss: 0.005979566802669086\n",
      "Validation Loss: 0.005925764437088534\n",
      "Epoch 5/25, Loss: 0.005043916749160674\n",
      "Validation Loss: 0.004843767300269618\n",
      "Epoch 6/25, Loss: 0.004305409632125321\n",
      "Validation Loss: 0.0042060532645933095\n",
      "Epoch 7/25, Loss: 0.0038033735319915616\n",
      "Validation Loss: 0.003924991747921683\n",
      "Epoch 8/25, Loss: 0.0034183323161079532\n",
      "Validation Loss: 0.003629595809122062\n",
      "Epoch 9/25, Loss: 0.0031315636839199168\n",
      "Validation Loss: 0.0034625559716095294\n",
      "Epoch 10/25, Loss: 0.002894215363364116\n",
      "Validation Loss: 0.0032277309271353982\n",
      "Epoch 11/25, Loss: 0.0027028359423574124\n",
      "Validation Loss: 0.003178962210450933\n",
      "Epoch 12/25, Loss: 0.0025374511488138823\n",
      "Validation Loss: 0.0030766230236733065\n",
      "Epoch 13/25, Loss: 0.0023866224250818345\n",
      "Validation Loss: 0.0029938458044761205\n",
      "Epoch 14/25, Loss: 0.002261924501878259\n",
      "Validation Loss: 0.0029765669450911437\n",
      "Epoch 15/25, Loss: 0.0021525355243222043\n",
      "Validation Loss: 0.0028218158465493663\n",
      "Epoch 16/25, Loss: 0.0020431188365648114\n",
      "Validation Loss: 0.002879363205003288\n",
      "Epoch 17/25, Loss: 0.0019523262019306147\n",
      "Validation Loss: 0.0027412670199193972\n",
      "Epoch 18/25, Loss: 0.0018631351787945377\n",
      "Validation Loss: 0.002739686409415536\n",
      "Epoch 19/25, Loss: 0.001785269417863673\n",
      "Validation Loss: 0.0026935525194595146\n",
      "Epoch 20/25, Loss: 0.0017078359342190485\n",
      "Validation Loss: 0.0025962973429223893\n",
      "Epoch 21/25, Loss: 0.001639567192371689\n",
      "Validation Loss: 0.002626786240514876\n",
      "Epoch 22/25, Loss: 0.001577151649367755\n",
      "Validation Loss: 0.0025877027251075234\n",
      "Epoch 23/25, Loss: 0.0015183803998162597\n",
      "Validation Loss: 0.002616946931763945\n",
      "Epoch 24/25, Loss: 0.0014603699341674064\n",
      "Validation Loss: 0.002565238618894334\n",
      "Epoch 25/25, Loss: 0.0014047892316085575\n",
      "Validation Loss: 0.0025510820063630855\n",
      "Fold 5/5\n",
      "Epoch 1/25, Loss: 0.016867266091664113\n",
      "Validation Loss: 0.011373504511240987\n",
      "Epoch 2/25, Loss: 0.009959597537645516\n",
      "Validation Loss: 0.009011778633535018\n",
      "Epoch 3/25, Loss: 0.008248292253243292\n",
      "Validation Loss: 0.007767667320725538\n",
      "Epoch 4/25, Loss: 0.007191094583410478\n",
      "Validation Loss: 0.0068154441837376565\n",
      "Epoch 5/25, Loss: 0.006357503096758709\n",
      "Validation Loss: 0.006746648117374821\n",
      "Epoch 6/25, Loss: 0.00580358413699595\n",
      "Validation Loss: 0.0057500318791458655\n",
      "Epoch 7/25, Loss: 0.005204742996100637\n",
      "Validation Loss: 0.005249598109521282\n",
      "Epoch 8/25, Loss: 0.0047984820605468\n",
      "Validation Loss: 0.004953558412535452\n",
      "Epoch 9/25, Loss: 0.004450494396640197\n",
      "Validation Loss: 0.004691374666534046\n",
      "Epoch 10/25, Loss: 0.00418944554223488\n",
      "Validation Loss: 0.0045892219261683765\n",
      "Epoch 11/25, Loss: 0.003935843670250474\n",
      "Validation Loss: 0.004313842111157596\n",
      "Epoch 12/25, Loss: 0.003715397710281009\n",
      "Validation Loss: 0.0040654024207573665\n",
      "Epoch 13/25, Loss: 0.0034692187713039027\n",
      "Validation Loss: 0.00393228560372824\n",
      "Epoch 14/25, Loss: 0.003249463428843445\n",
      "Validation Loss: 0.003890410400775791\n",
      "Epoch 15/25, Loss: 0.003097897039416063\n",
      "Validation Loss: 0.0037652384295190017\n",
      "Epoch 16/25, Loss: 0.002988226847647645\n",
      "Validation Loss: 0.0036854884541601546\n",
      "Epoch 17/25, Loss: 0.002877702858498014\n",
      "Validation Loss: 0.003560469439765597\n",
      "Epoch 18/25, Loss: 0.002743511344073626\n",
      "Validation Loss: 0.0034964784550025984\n",
      "Epoch 19/25, Loss: 0.0026380312361731985\n",
      "Validation Loss: 0.0034577891653057658\n",
      "Epoch 20/25, Loss: 0.0025592186402703314\n",
      "Validation Loss: 0.003478751665631244\n",
      "Epoch 21/25, Loss: 0.002462104561209154\n",
      "Validation Loss: 0.0033428883134883473\n",
      "Epoch 22/25, Loss: 0.002357305766091306\n",
      "Validation Loss: 0.003291494654123602\n",
      "Epoch 23/25, Loss: 0.002278186301847541\n",
      "Validation Loss: 0.003201624615723499\n",
      "Epoch 24/25, Loss: 0.0022097051377620545\n",
      "Validation Loss: 0.0032149177877379316\n",
      "Epoch 25/25, Loss: 0.0021172134595192327\n",
      "Validation Loss: 0.0031430810664428844\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal para cargar datos y ejecutar validación cruzada.\n",
    "    \"\"\"\n",
    "    annotations_path = '../mnt/V3/annotations/annotations_preprocessed.json'\n",
    "    image_dir = '../mnt/V3/images'\n",
    "\n",
    "    annotations = load_annotations(annotations_path)\n",
    "\n",
    "    dataset = SkeletonDataset(annotations, image_dir=image_dir, transform=data_transforms)\n",
    "\n",
    "    cross_validation_kfold(dataset, k_folds=5, batch_size=8, num_epochs=15, patience=3)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

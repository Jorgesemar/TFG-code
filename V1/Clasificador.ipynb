{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para mapear posiciones a índices\n",
    "position_to_index = {\n",
    "    '5050_guard': 0,\n",
    "    'back1': 1,\n",
    "    'back2': 2,\n",
    "    'closed_guard1': 3,\n",
    "    'closed_guard2': 4,\n",
    "    'half_guard1': 5,\n",
    "    'half_guard2': 6,\n",
    "    'mount1': 7,\n",
    "    'mount2': 8,\n",
    "    'open_guard1': 9,\n",
    "    'open_guard2': 10,\n",
    "    'side_control1': 11,\n",
    "    'side_control2': 12,\n",
    "    'standing': 13,\n",
    "    'takedown1': 14,\n",
    "    'takedown2': 15,\n",
    "    'turtle1': 16,\n",
    "    'turtle2': 17\n",
    "}\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(file_path):\n",
    "    \"\"\"\n",
    "    Carga las anotaciones preprocesadas desde un archivo JSON.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BJJDataset(Dataset):\n",
    "    def __init__(self, annotations, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Inicializa el dataset con transformaciones y rutas a imágenes.\n",
    "        \"\"\"\n",
    "        self.annotations = annotations\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.annotations[idx]['Image'] + '.jpg'\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        label_str = self.annotations[idx]['Position']\n",
    "        label = position_to_index[label_str]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label).long()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, device):\n",
    "    \"\"\"\n",
    "    Inicializa el modelo ResNet-18 y lo prepara para entrenamiento.\n",
    "    \"\"\"\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Realiza una época de entrenamiento en el modelo.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    return running_loss / len(train_loader.dataset), correct.double() / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Realiza una época de validación en el modelo y calcula métricas adicionales.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    std_ae = np.std(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "\n",
    "    print(f\"Validation Metrics -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, \"\n",
    "          f\"MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}, Std_AE: {std_ae:.4f}\")\n",
    "\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_kfold(dataset, num_classes, k_folds=5, num_epochs=25, batch_size=32, early_stopping_patience=5):\n",
    "    \"\"\"\n",
    "    Entrena el modelo ResNet-18 utilizando validación cruzada con K-Fold.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "        # Dividir dataset en subconjuntos de entrenamiento y validación\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "\n",
    "        # Inicializar modelo, criterio, optimizador y scheduler\n",
    "        model = initialize_model(num_classes, device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Entrenamiento\n",
    "            epoch_loss, epoch_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "            # Validación\n",
    "            val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
    "            print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "            # Early Stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                early_stopping_counter = 0\n",
    "                torch.save(model.state_dict(), f'model_fold_{fold+1}.pth')\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                if early_stopping_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/25, Loss: 0.3802, Accuracy: 0.8794\n",
      "Validation Metrics -> Loss: 0.8345, Accuracy: 0.7652, MAE: 1.7837, MSE: 16.8840, R²: 0.3633, Std_AE: 3.7017\n",
      "Validation Loss: 0.8345, Validation Accuracy: 0.7652\n",
      "Epoch 2/25, Loss: 0.1091, Accuracy: 0.9657\n",
      "Validation Metrics -> Loss: 0.0773, Accuracy: 0.9733, MAE: 0.0980, MSE: 0.6213, R²: 0.9766, Std_AE: 0.7821\n",
      "Validation Loss: 0.0773, Validation Accuracy: 0.9733\n",
      "Epoch 3/25, Loss: 0.0677, Accuracy: 0.9788\n",
      "Validation Metrics -> Loss: 0.2737, Accuracy: 0.9250, MAE: 0.4398, MSE: 3.8565, R²: 0.8546, Std_AE: 1.9139\n",
      "Validation Loss: 0.2737, Validation Accuracy: 0.9250\n",
      "Epoch 4/25, Loss: 0.0501, Accuracy: 0.9838\n",
      "Validation Metrics -> Loss: 0.0718, Accuracy: 0.9760, MAE: 0.1082, MSE: 0.8388, R²: 0.9684, Std_AE: 0.9095\n",
      "Validation Loss: 0.0718, Validation Accuracy: 0.9760\n",
      "Epoch 5/25, Loss: 0.0454, Accuracy: 0.9860\n",
      "Validation Metrics -> Loss: 0.0427, Accuracy: 0.9868, MAE: 0.0558, MSE: 0.4768, R²: 0.9820, Std_AE: 0.6883\n",
      "Validation Loss: 0.0427, Validation Accuracy: 0.9868\n",
      "Epoch 6/25, Loss: 0.0388, Accuracy: 0.9883\n",
      "Validation Metrics -> Loss: 0.0753, Accuracy: 0.9783, MAE: 0.0960, MSE: 0.7327, R²: 0.9724, Std_AE: 0.8506\n",
      "Validation Loss: 0.0753, Validation Accuracy: 0.9783\n",
      "Epoch 7/25, Loss: 0.0337, Accuracy: 0.9894\n",
      "Validation Metrics -> Loss: 0.0548, Accuracy: 0.9843, MAE: 0.0650, MSE: 0.4880, R²: 0.9816, Std_AE: 0.6955\n",
      "Validation Loss: 0.0548, Validation Accuracy: 0.9843\n",
      "Epoch 8/25, Loss: 0.0311, Accuracy: 0.9898\n",
      "Validation Metrics -> Loss: 0.0572, Accuracy: 0.9842, MAE: 0.0735, MSE: 0.6572, R²: 0.9752, Std_AE: 0.8073\n",
      "Validation Loss: 0.0572, Validation Accuracy: 0.9842\n",
      "Epoch 9/25, Loss: 0.0282, Accuracy: 0.9923\n",
      "Validation Metrics -> Loss: 0.0491, Accuracy: 0.9865, MAE: 0.0487, MSE: 0.3000, R²: 0.9887, Std_AE: 0.5456\n",
      "Validation Loss: 0.0491, Validation Accuracy: 0.9865\n",
      "Epoch 10/25, Loss: 0.0209, Accuracy: 0.9938\n",
      "Validation Metrics -> Loss: 0.0409, Accuracy: 0.9902, MAE: 0.0490, MSE: 0.4240, R²: 0.9840, Std_AE: 0.6493\n",
      "Validation Loss: 0.0409, Validation Accuracy: 0.9902\n",
      "Epoch 11/25, Loss: 0.0233, Accuracy: 0.9934\n",
      "Validation Metrics -> Loss: 0.0857, Accuracy: 0.9812, MAE: 0.0905, MSE: 0.6768, R²: 0.9745, Std_AE: 0.8177\n",
      "Validation Loss: 0.0857, Validation Accuracy: 0.9812\n",
      "Epoch 12/25, Loss: 0.0229, Accuracy: 0.9930\n",
      "Validation Metrics -> Loss: 0.0480, Accuracy: 0.9882, MAE: 0.0505, MSE: 0.3872, R²: 0.9854, Std_AE: 0.6202\n",
      "Validation Loss: 0.0480, Validation Accuracy: 0.9882\n",
      "Epoch 13/25, Loss: 0.0167, Accuracy: 0.9947\n",
      "Validation Metrics -> Loss: 0.0521, Accuracy: 0.9868, MAE: 0.0743, MSE: 0.7243, R²: 0.9727, Std_AE: 0.8478\n",
      "Validation Loss: 0.0521, Validation Accuracy: 0.9868\n",
      "Epoch 14/25, Loss: 0.0185, Accuracy: 0.9943\n",
      "Validation Metrics -> Loss: 0.0513, Accuracy: 0.9867, MAE: 0.0725, MSE: 0.6062, R²: 0.9771, Std_AE: 0.7752\n",
      "Validation Loss: 0.0513, Validation Accuracy: 0.9867\n",
      "Epoch 15/25, Loss: 0.0168, Accuracy: 0.9949\n",
      "Validation Metrics -> Loss: 0.0379, Accuracy: 0.9917, MAE: 0.0237, MSE: 0.1167, R²: 0.9956, Std_AE: 0.3407\n",
      "Validation Loss: 0.0379, Validation Accuracy: 0.9917\n",
      "Epoch 16/25, Loss: 0.0130, Accuracy: 0.9967\n",
      "Validation Metrics -> Loss: 0.0922, Accuracy: 0.9805, MAE: 0.0862, MSE: 0.6432, R²: 0.9757, Std_AE: 0.7973\n",
      "Validation Loss: 0.0922, Validation Accuracy: 0.9805\n",
      "Epoch 17/25, Loss: 0.0144, Accuracy: 0.9953\n",
      "Validation Metrics -> Loss: 0.1116, Accuracy: 0.9732, MAE: 0.0992, MSE: 0.7268, R²: 0.9726, Std_AE: 0.8468\n",
      "Validation Loss: 0.1116, Validation Accuracy: 0.9732\n",
      "Epoch 18/25, Loss: 0.0141, Accuracy: 0.9954\n",
      "Validation Metrics -> Loss: 0.0387, Accuracy: 0.9920, MAE: 0.0262, MSE: 0.1832, R²: 0.9931, Std_AE: 0.4272\n",
      "Validation Loss: 0.0387, Validation Accuracy: 0.9920\n",
      "Epoch 19/25, Loss: 0.0072, Accuracy: 0.9982\n",
      "Validation Metrics -> Loss: 0.0589, Accuracy: 0.9885, MAE: 0.0360, MSE: 0.2567, R²: 0.9903, Std_AE: 0.5053\n",
      "Validation Loss: 0.0589, Validation Accuracy: 0.9885\n",
      "Epoch 20/25, Loss: 0.0125, Accuracy: 0.9964\n",
      "Validation Metrics -> Loss: 0.0857, Accuracy: 0.9803, MAE: 0.1038, MSE: 0.8272, R²: 0.9688, Std_AE: 0.9035\n",
      "Validation Loss: 0.0857, Validation Accuracy: 0.9803\n",
      "Early stopping\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.3510, Accuracy: 0.8871\n",
      "Validation Metrics -> Loss: 0.3882, Accuracy: 0.8880, MAE: 0.6490, MSE: 6.0250, R²: 0.7749, Std_AE: 2.3672\n",
      "Validation Loss: 0.3882, Validation Accuracy: 0.8880\n",
      "Epoch 2/25, Loss: 0.0947, Accuracy: 0.9706\n",
      "Validation Metrics -> Loss: 0.2508, Accuracy: 0.9133, MAE: 0.4293, MSE: 3.2140, R²: 0.8799, Std_AE: 1.7406\n",
      "Validation Loss: 0.2508, Validation Accuracy: 0.9133\n",
      "Epoch 3/25, Loss: 0.0736, Accuracy: 0.9758\n",
      "Validation Metrics -> Loss: 0.0542, Accuracy: 0.9858, MAE: 0.0542, MSE: 0.3322, R²: 0.9876, Std_AE: 0.5738\n",
      "Validation Loss: 0.0542, Validation Accuracy: 0.9858\n",
      "Epoch 4/25, Loss: 0.0587, Accuracy: 0.9808\n",
      "Validation Metrics -> Loss: 0.0727, Accuracy: 0.9772, MAE: 0.0958, MSE: 0.6428, R²: 0.9760, Std_AE: 0.7960\n",
      "Validation Loss: 0.0727, Validation Accuracy: 0.9772\n",
      "Epoch 5/25, Loss: 0.0259, Accuracy: 0.9916\n",
      "Validation Metrics -> Loss: 0.0459, Accuracy: 0.9863, MAE: 0.0563, MSE: 0.4170, R²: 0.9844, Std_AE: 0.6433\n",
      "Validation Loss: 0.0459, Validation Accuracy: 0.9863\n",
      "Epoch 6/25, Loss: 0.0476, Accuracy: 0.9848\n",
      "Validation Metrics -> Loss: 0.0669, Accuracy: 0.9800, MAE: 0.0637, MSE: 0.3860, R²: 0.9856, Std_AE: 0.6180\n",
      "Validation Loss: 0.0669, Validation Accuracy: 0.9800\n",
      "Epoch 7/25, Loss: 0.0341, Accuracy: 0.9893\n",
      "Validation Metrics -> Loss: 0.1072, Accuracy: 0.9677, MAE: 0.1657, MSE: 1.2547, R²: 0.9531, Std_AE: 1.1078\n",
      "Validation Loss: 0.1072, Validation Accuracy: 0.9677\n",
      "Epoch 8/25, Loss: 0.0250, Accuracy: 0.9929\n",
      "Validation Metrics -> Loss: 0.0268, Accuracy: 0.9918, MAE: 0.0263, MSE: 0.1753, R²: 0.9935, Std_AE: 0.4179\n",
      "Validation Loss: 0.0268, Validation Accuracy: 0.9918\n",
      "Epoch 9/25, Loss: 0.0252, Accuracy: 0.9925\n",
      "Validation Metrics -> Loss: 0.1302, Accuracy: 0.9577, MAE: 0.1543, MSE: 1.0903, R²: 0.9593, Std_AE: 1.0327\n",
      "Validation Loss: 0.1302, Validation Accuracy: 0.9577\n",
      "Epoch 10/25, Loss: 0.0246, Accuracy: 0.9922\n",
      "Validation Metrics -> Loss: 0.0319, Accuracy: 0.9907, MAE: 0.0483, MSE: 0.4173, R²: 0.9844, Std_AE: 0.6442\n",
      "Validation Loss: 0.0319, Validation Accuracy: 0.9907\n",
      "Epoch 11/25, Loss: 0.0102, Accuracy: 0.9969\n",
      "Validation Metrics -> Loss: 0.0252, Accuracy: 0.9940, MAE: 0.0242, MSE: 0.1455, R²: 0.9946, Std_AE: 0.3807\n",
      "Validation Loss: 0.0252, Validation Accuracy: 0.9940\n",
      "Epoch 12/25, Loss: 0.0282, Accuracy: 0.9920\n",
      "Validation Metrics -> Loss: 0.0497, Accuracy: 0.9875, MAE: 0.0558, MSE: 0.4018, R²: 0.9850, Std_AE: 0.6314\n",
      "Validation Loss: 0.0497, Validation Accuracy: 0.9875\n",
      "Epoch 13/25, Loss: 0.0229, Accuracy: 0.9934\n",
      "Validation Metrics -> Loss: 0.0380, Accuracy: 0.9897, MAE: 0.0585, MSE: 0.5282, R²: 0.9803, Std_AE: 0.7244\n",
      "Validation Loss: 0.0380, Validation Accuracy: 0.9897\n",
      "Epoch 14/25, Loss: 0.0115, Accuracy: 0.9967\n",
      "Validation Metrics -> Loss: 0.0171, Accuracy: 0.9947, MAE: 0.0185, MSE: 0.0985, R²: 0.9963, Std_AE: 0.3133\n",
      "Validation Loss: 0.0171, Validation Accuracy: 0.9947\n",
      "Epoch 15/25, Loss: 0.0193, Accuracy: 0.9942\n",
      "Validation Metrics -> Loss: 0.0403, Accuracy: 0.9888, MAE: 0.0375, MSE: 0.2485, R²: 0.9907, Std_AE: 0.4971\n",
      "Validation Loss: 0.0403, Validation Accuracy: 0.9888\n",
      "Epoch 16/25, Loss: 0.0116, Accuracy: 0.9964\n",
      "Validation Metrics -> Loss: 0.0262, Accuracy: 0.9938, MAE: 0.0218, MSE: 0.1225, R²: 0.9954, Std_AE: 0.3493\n",
      "Validation Loss: 0.0262, Validation Accuracy: 0.9938\n",
      "Epoch 17/25, Loss: 0.0034, Accuracy: 0.9992\n",
      "Validation Metrics -> Loss: 0.0169, Accuracy: 0.9958, MAE: 0.0177, MSE: 0.1240, R²: 0.9954, Std_AE: 0.3517\n",
      "Validation Loss: 0.0169, Validation Accuracy: 0.9958\n",
      "Epoch 18/25, Loss: 0.0336, Accuracy: 0.9908\n",
      "Validation Metrics -> Loss: 0.0213, Accuracy: 0.9942, MAE: 0.0222, MSE: 0.1542, R²: 0.9942, Std_AE: 0.3920\n",
      "Validation Loss: 0.0213, Validation Accuracy: 0.9942\n",
      "Epoch 19/25, Loss: 0.0064, Accuracy: 0.9982\n",
      "Validation Metrics -> Loss: 0.0203, Accuracy: 0.9957, MAE: 0.0147, MSE: 0.0767, R²: 0.9971, Std_AE: 0.2765\n",
      "Validation Loss: 0.0203, Validation Accuracy: 0.9957\n",
      "Epoch 20/25, Loss: 0.0112, Accuracy: 0.9966\n",
      "Validation Metrics -> Loss: 0.0499, Accuracy: 0.9885, MAE: 0.0500, MSE: 0.3087, R²: 0.9885, Std_AE: 0.5533\n",
      "Validation Loss: 0.0499, Validation Accuracy: 0.9885\n",
      "Epoch 21/25, Loss: 0.0124, Accuracy: 0.9965\n",
      "Validation Metrics -> Loss: 0.0368, Accuracy: 0.9910, MAE: 0.0352, MSE: 0.2298, R²: 0.9914, Std_AE: 0.4781\n",
      "Validation Loss: 0.0368, Validation Accuracy: 0.9910\n",
      "Epoch 22/25, Loss: 0.0170, Accuracy: 0.9954\n",
      "Validation Metrics -> Loss: 0.0279, Accuracy: 0.9935, MAE: 0.0348, MSE: 0.2875, R²: 0.9893, Std_AE: 0.5351\n",
      "Validation Loss: 0.0279, Validation Accuracy: 0.9935\n",
      "Early stopping\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.3468, Accuracy: 0.8912\n",
      "Validation Metrics -> Loss: 0.2263, Accuracy: 0.9330, MAE: 0.2852, MSE: 1.9418, R²: 0.9276, Std_AE: 1.3640\n",
      "Validation Loss: 0.2263, Validation Accuracy: 0.9330\n",
      "Epoch 2/25, Loss: 0.0995, Accuracy: 0.9683\n",
      "Validation Metrics -> Loss: 0.1488, Accuracy: 0.9498, MAE: 0.2522, MSE: 2.1248, R²: 0.9207, Std_AE: 1.4357\n",
      "Validation Loss: 0.1488, Validation Accuracy: 0.9498\n",
      "Epoch 3/25, Loss: 0.0601, Accuracy: 0.9808\n",
      "Validation Metrics -> Loss: 0.0609, Accuracy: 0.9828, MAE: 0.0672, MSE: 0.4898, R²: 0.9817, Std_AE: 0.6967\n",
      "Validation Loss: 0.0609, Validation Accuracy: 0.9828\n",
      "Epoch 4/25, Loss: 0.0588, Accuracy: 0.9809\n",
      "Validation Metrics -> Loss: 0.0533, Accuracy: 0.9827, MAE: 0.0655, MSE: 0.4908, R²: 0.9817, Std_AE: 0.6975\n",
      "Validation Loss: 0.0533, Validation Accuracy: 0.9827\n",
      "Epoch 5/25, Loss: 0.0361, Accuracy: 0.9885\n",
      "Validation Metrics -> Loss: 0.0616, Accuracy: 0.9828, MAE: 0.0630, MSE: 0.5163, R²: 0.9807, Std_AE: 0.7158\n",
      "Validation Loss: 0.0616, Validation Accuracy: 0.9828\n",
      "Epoch 6/25, Loss: 0.0397, Accuracy: 0.9876\n",
      "Validation Metrics -> Loss: 0.0676, Accuracy: 0.9798, MAE: 0.0807, MSE: 0.5130, R²: 0.9809, Std_AE: 0.7117\n",
      "Validation Loss: 0.0676, Validation Accuracy: 0.9798\n",
      "Epoch 7/25, Loss: 0.0347, Accuracy: 0.9895\n",
      "Validation Metrics -> Loss: 0.2846, Accuracy: 0.9313, MAE: 0.5050, MSE: 5.8260, R²: 0.7827, Std_AE: 2.3603\n",
      "Validation Loss: 0.2846, Validation Accuracy: 0.9313\n",
      "Epoch 8/25, Loss: 0.0272, Accuracy: 0.9920\n",
      "Validation Metrics -> Loss: 0.0682, Accuracy: 0.9773, MAE: 0.1020, MSE: 0.7013, R²: 0.9738, Std_AE: 0.8312\n",
      "Validation Loss: 0.0682, Validation Accuracy: 0.9773\n",
      "Epoch 9/25, Loss: 0.0262, Accuracy: 0.9926\n",
      "Validation Metrics -> Loss: 0.1185, Accuracy: 0.9692, MAE: 0.1438, MSE: 0.9655, R²: 0.9640, Std_AE: 0.9720\n",
      "Validation Loss: 0.1185, Validation Accuracy: 0.9692\n",
      "Early stopping\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.3516, Accuracy: 0.8896\n",
      "Validation Metrics -> Loss: 0.1756, Accuracy: 0.9420, MAE: 0.2192, MSE: 1.4265, R²: 0.9463, Std_AE: 1.1741\n",
      "Validation Loss: 0.1756, Validation Accuracy: 0.9420\n",
      "Epoch 2/25, Loss: 0.1029, Accuracy: 0.9670\n",
      "Validation Metrics -> Loss: 0.1670, Accuracy: 0.9475, MAE: 0.2368, MSE: 2.0968, R²: 0.9211, Std_AE: 1.4285\n",
      "Validation Loss: 0.1670, Validation Accuracy: 0.9475\n",
      "Epoch 3/25, Loss: 0.0621, Accuracy: 0.9797\n",
      "Validation Metrics -> Loss: 0.1659, Accuracy: 0.9438, MAE: 0.2160, MSE: 1.4780, R²: 0.9444, Std_AE: 1.1964\n",
      "Validation Loss: 0.1659, Validation Accuracy: 0.9438\n",
      "Epoch 4/25, Loss: 0.0524, Accuracy: 0.9835\n",
      "Validation Metrics -> Loss: 0.1199, Accuracy: 0.9695, MAE: 0.1225, MSE: 0.9178, R²: 0.9654, Std_AE: 0.9502\n",
      "Validation Loss: 0.1199, Validation Accuracy: 0.9695\n",
      "Epoch 5/25, Loss: 0.0402, Accuracy: 0.9880\n",
      "Validation Metrics -> Loss: 0.0328, Accuracy: 0.9892, MAE: 0.0418, MSE: 0.2852, R²: 0.9893, Std_AE: 0.5324\n",
      "Validation Loss: 0.0328, Validation Accuracy: 0.9892\n",
      "Epoch 6/25, Loss: 0.0377, Accuracy: 0.9874\n",
      "Validation Metrics -> Loss: 0.0621, Accuracy: 0.9822, MAE: 0.0858, MSE: 0.6862, R²: 0.9742, Std_AE: 0.8239\n",
      "Validation Loss: 0.0621, Validation Accuracy: 0.9822\n",
      "Epoch 7/25, Loss: 0.0235, Accuracy: 0.9930\n",
      "Validation Metrics -> Loss: 2.4432, Accuracy: 0.6492, MAE: 2.7992, MSE: 28.7428, R²: -0.0821, Std_AE: 4.5725\n",
      "Validation Loss: 2.4432, Validation Accuracy: 0.6492\n",
      "Epoch 8/25, Loss: 0.0371, Accuracy: 0.9886\n",
      "Validation Metrics -> Loss: 0.1552, Accuracy: 0.9672, MAE: 0.1172, MSE: 0.7985, R²: 0.9699, Std_AE: 0.8859\n",
      "Validation Loss: 0.1552, Validation Accuracy: 0.9672\n",
      "Epoch 9/25, Loss: 0.0200, Accuracy: 0.9942\n",
      "Validation Metrics -> Loss: 0.0433, Accuracy: 0.9888, MAE: 0.0463, MSE: 0.2907, R²: 0.9891, Std_AE: 0.5371\n",
      "Validation Loss: 0.0433, Validation Accuracy: 0.9888\n",
      "Epoch 10/25, Loss: 0.0163, Accuracy: 0.9953\n",
      "Validation Metrics -> Loss: 0.0337, Accuracy: 0.9915, MAE: 0.0293, MSE: 0.2087, R²: 0.9921, Std_AE: 0.4559\n",
      "Validation Loss: 0.0337, Validation Accuracy: 0.9915\n",
      "Early stopping\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tuf Gaming\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.3596, Accuracy: 0.8847\n",
      "Validation Metrics -> Loss: 0.3725, Accuracy: 0.8935, MAE: 0.4788, MSE: 3.4622, R²: 0.8698, Std_AE: 1.7980\n",
      "Validation Loss: 0.3725, Validation Accuracy: 0.8935\n",
      "Epoch 2/25, Loss: 0.1024, Accuracy: 0.9664\n",
      "Validation Metrics -> Loss: 0.1023, Accuracy: 0.9638, MAE: 0.1685, MSE: 1.3062, R²: 0.9509, Std_AE: 1.1304\n",
      "Validation Loss: 0.1023, Validation Accuracy: 0.9638\n",
      "Epoch 3/25, Loss: 0.0712, Accuracy: 0.9768\n",
      "Validation Metrics -> Loss: 0.2320, Accuracy: 0.9192, MAE: 0.3530, MSE: 2.2050, R²: 0.9171, Std_AE: 1.4424\n",
      "Validation Loss: 0.2320, Validation Accuracy: 0.9192\n",
      "Epoch 4/25, Loss: 0.0500, Accuracy: 0.9845\n",
      "Validation Metrics -> Loss: 0.1011, Accuracy: 0.9653, MAE: 0.1380, MSE: 0.8983, R²: 0.9662, Std_AE: 0.9377\n",
      "Validation Loss: 0.1011, Validation Accuracy: 0.9653\n",
      "Epoch 5/25, Loss: 0.0299, Accuracy: 0.9906\n",
      "Validation Metrics -> Loss: 0.2323, Accuracy: 0.9403, MAE: 0.2848, MSE: 2.3545, R²: 0.9115, Std_AE: 1.5078\n",
      "Validation Loss: 0.2323, Validation Accuracy: 0.9403\n",
      "Epoch 6/25, Loss: 0.0526, Accuracy: 0.9839\n",
      "Validation Metrics -> Loss: 0.0469, Accuracy: 0.9873, MAE: 0.0402, MSE: 0.2332, R²: 0.9912, Std_AE: 0.4812\n",
      "Validation Loss: 0.0469, Validation Accuracy: 0.9873\n",
      "Epoch 7/25, Loss: 0.0238, Accuracy: 0.9928\n",
      "Validation Metrics -> Loss: 0.0880, Accuracy: 0.9743, MAE: 0.0837, MSE: 0.4483, R²: 0.9831, Std_AE: 0.6643\n",
      "Validation Loss: 0.0880, Validation Accuracy: 0.9743\n",
      "Epoch 8/25, Loss: 0.0349, Accuracy: 0.9891\n",
      "Validation Metrics -> Loss: 0.0968, Accuracy: 0.9758, MAE: 0.0880, MSE: 0.7130, R²: 0.9732, Std_AE: 0.8398\n",
      "Validation Loss: 0.0968, Validation Accuracy: 0.9758\n",
      "Epoch 9/25, Loss: 0.0324, Accuracy: 0.9898\n",
      "Validation Metrics -> Loss: 0.0708, Accuracy: 0.9805, MAE: 0.0852, MSE: 0.5528, R²: 0.9792, Std_AE: 0.7386\n",
      "Validation Loss: 0.0708, Validation Accuracy: 0.9805\n",
      "Epoch 10/25, Loss: 0.0147, Accuracy: 0.9959\n",
      "Validation Metrics -> Loss: 0.0581, Accuracy: 0.9837, MAE: 0.0760, MSE: 0.5983, R²: 0.9775, Std_AE: 0.7698\n",
      "Validation Loss: 0.0581, Validation Accuracy: 0.9837\n",
      "Epoch 11/25, Loss: 0.0296, Accuracy: 0.9908\n",
      "Validation Metrics -> Loss: 0.0747, Accuracy: 0.9802, MAE: 0.1007, MSE: 0.8630, R²: 0.9675, Std_AE: 0.9235\n",
      "Validation Loss: 0.0747, Validation Accuracy: 0.9802\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal para cargar el dataset y entrenar el modelo con validación cruzada.\n",
    "    \"\"\"\n",
    "    annotations_path = '../mnt/V1/annotations/annotations_preprocessed.json'\n",
    "    image_dir = '../mnt/V1/images'\n",
    "\n",
    "    # Cargar anotaciones\n",
    "    annotations = load_annotations(annotations_path)\n",
    "\n",
    "    # Cargar el dataset completo\n",
    "    dataset = BJJDataset(annotations, image_dir, transform=data_transforms)\n",
    "\n",
    "    # Entrenar modelo con validación cruzada\n",
    "    train_model_kfold(dataset, num_classes=len(position_to_index))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

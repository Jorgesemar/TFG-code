{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video creado y guardado en: ./output_predictions_video_v2.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Diccionario de clases\n",
    "position_to_index = {\n",
    "    '5050_guard': 0,\n",
    "    'back1': 1,\n",
    "    'back2': 2,\n",
    "    'closed_guard1': 3,\n",
    "    'closed_guard2': 4,\n",
    "    'half_guard1': 5,\n",
    "    'half_guard2': 6,\n",
    "    'mount1': 7,\n",
    "    'mount2': 8,\n",
    "    'open_guard1': 9,\n",
    "    'open_guard2': 10,\n",
    "    'side_control1': 11,\n",
    "    'side_control2': 12,\n",
    "    'standing': 13,\n",
    "    'takedown1': 14,\n",
    "    'takedown2': 15,\n",
    "    'turtle1': 16,\n",
    "    'turtle2': 17\n",
    "}\n",
    "index_to_position = {v: k for k, v in position_to_index.items()}\n",
    "\n",
    "# Rutas de los modelos\n",
    "hrnet_model_path = './V2/Models/Hrnet_Models/hrnet_best_model.pth'\n",
    "lstm_model_path = './V2/Models/Lstm_Models/best_lstm_model.pth'\n",
    "resnet_model_path = './V2/Models/Resnet_Models/model_fold_3.pth'\n",
    "image_dir = './mnt/Dataset/images'\n",
    "\n",
    "# Cargar modelos\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Modelo de predicción de pose (HRNet)\n",
    "class HRNetForPose(nn.Module):\n",
    "    def __init__(self, num_keypoints=102):\n",
    "        super(HRNetForPose, self).__init__()\n",
    "        self.backbone = deeplabv3_resnet50(pretrained=False).backbone\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(2048, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, num_keypoints, kernel_size=1, stride=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)['out']\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "hrnet_model = HRNetForPose(num_keypoints=102).to(device)\n",
    "hrnet_model.load_state_dict(torch.load(hrnet_model_path, map_location=device))\n",
    "hrnet_model.eval()\n",
    "\n",
    "# Modelo de análisis de secuencia (LSTM)\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        final_output = lstm_out[:, -1, :]\n",
    "        out = self.fc(final_output)\n",
    "        return out\n",
    "\n",
    "input_size = 102\n",
    "hidden_size = 128\n",
    "output_size = 18\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "lstm_model.load_state_dict(torch.load(lstm_model_path, map_location=device))\n",
    "lstm_model.eval()\n",
    "\n",
    "# Modelo de clasificación de imagen (ResNet)\n",
    "resnet_model = models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 18)\n",
    "resnet_model.load_state_dict(torch.load(resnet_model_path, map_location=device))\n",
    "resnet_model = resnet_model.to(device)\n",
    "resnet_model.eval()\n",
    "\n",
    "# Transformaciones para el modelo ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Conexiones para dibujar esqueleto\n",
    "skeleton_connections = [\n",
    "    (0, 1), (0, 2), (1, 3), (2, 4),\n",
    "    (5, 6), (5, 7), (7, 9),\n",
    "    (6, 8), (8, 10), (11, 12),\n",
    "    (11, 13), (13, 15), (12, 14),\n",
    "    (14, 16)\n",
    "]\n",
    "\n",
    "# Función para dibujar esqueletos\n",
    "def draw_skeleton(pose, img_shape, color='r'):\n",
    "    pose = np.array(pose)\n",
    "    img_h, img_w = img_shape[:2]\n",
    "    \n",
    "    for (x, y, c) in pose:\n",
    "        if c > 0.5:\n",
    "            plt.plot(x * img_w, y * img_h, 'o', color=color, markersize=5)\n",
    "\n",
    "    for connection in skeleton_connections:\n",
    "        p1, p2 = connection\n",
    "        if pose[p1][2] > 0.5 and pose[p2][2] > 0.5:\n",
    "            plt.plot([pose[p1][0] * img_w, pose[p2][0] * img_w],\n",
    "                     [pose[p1][1] * img_h, pose[p2][1] * img_h], color=color, linewidth=2)\n",
    "\n",
    "# Crear el video con predicciones y esqueleto dibujado\n",
    "def create_video_with_predictions(image_dir, output_video_path):\n",
    "    seq_length = 10\n",
    "    images = sorted(os.listdir(image_dir))\n",
    "    total_images = len(images)\n",
    "    if total_images < 300:\n",
    "        print(\"No hay suficientes imágenes en el directorio para seleccionar 100 imágenes consecutivas.\")\n",
    "        return\n",
    "\n",
    "    max_start_index = total_images - 300\n",
    "    start_index = random.randint(0, max_start_index)\n",
    "    selected_images = images[start_index:start_index + 300]\n",
    "\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 10, (512, 512))\n",
    "    \n",
    "    sequence = []\n",
    "    for image_name in selected_images:\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = Image.open(image_path).resize((256, 256))\n",
    "        \n",
    "        pose_input = transform(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            pose_output = hrnet_model(pose_input)\n",
    "        pose_keypoints = pose_output.view(34, 3).cpu().numpy()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            class_output = resnet_model(pose_input)\n",
    "        predicted_class = index_to_position[class_output.argmax(dim=1).item()]\n",
    "        \n",
    "        sequence.append(pose_keypoints.flatten())\n",
    "        if len(sequence) == seq_length:\n",
    "            sequence_tensor = torch.tensor(sequence).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                sequence_output = lstm_model(sequence_tensor)\n",
    "            sequence_class = index_to_position[sequence_output.argmax(dim=1).item()]\n",
    "            sequence.clear()\n",
    "        \n",
    "        # Dibujar usando Matplotlib para esqueleto\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(np.array(image))\n",
    "        draw_skeleton(pose_keypoints[:17], np.array(image).shape, color='r')  \n",
    "        draw_skeleton(pose_keypoints[17:], np.array(image).shape, color='b')  \n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Convertir plt a imagen para OpenCV\n",
    "        plt.savefig(\"temp_skeleton.png\", bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        \n",
    "        frame = cv2.imread(\"temp_skeleton.png\")\n",
    "        frame = cv2.resize(frame, (512, 512))\n",
    "        \n",
    "        # Añadir texto de predicciones\n",
    "        cv2.putText(frame, f\"Image Class: {predicted_class}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        if 'sequence_class' in locals():\n",
    "            cv2.putText(frame, f\"Sequence Class: {sequence_class}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        video_writer.write(frame)\n",
    "    \n",
    "    video_writer.release()\n",
    "    os.remove(\"temp_skeleton.png\")\n",
    "\n",
    "# Generar el video\n",
    "output_video_path = './output_predictions_video_v2.mp4'\n",
    "create_video_with_predictions(image_dir, output_video_path)\n",
    "print(f\"Video creado y guardado en: {output_video_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
